{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn import ensemble\n",
    "from sklearn import datasets\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv((\n",
    "    \"https://raw.githubusercontent.com/Thinkful-Ed/data-201-resources/\"\n",
    "    \"master/ESS_practice_data/ESSdata_Thinkful.csv\")).dropna()\n",
    "\n",
    "# Definine outcome and predictors.\n",
    "# Set our outcome to 0 and 1.\n",
    "y = df['partner'] - 1\n",
    "X = df.loc[:, ~df.columns.isin(['partner', 'cntry', 'idno'])]\n",
    "\n",
    "# Make the categorical variable 'country' into dummies.\n",
    "X = pd.concat([X, pd.get_dummies(df['cntry'])], axis=1)\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(kind = \"regular\")\n",
    "X_sm, Y_sm = smote.fit_sample(X,y)\n",
    "\n",
    "sm_features = pd.DataFrame(data=X_sm,columns=X.columns)\n",
    "\n",
    "sm_target = pd.DataFrame(data=Y_sm, columns = ['partner'])\n",
    "\n",
    "frames = [sm_features, sm_target]\n",
    "sm_data = pd.concat(frames,axis=1)\n",
    "\n",
    "X = sm_features\n",
    "y = sm_target.values.ravel()\n",
    "\n",
    "# Create training and test sets.\n",
    "offset = int(X.shape[0] * 0.7)\n",
    "\n",
    "# Put 90% of the data in the training set.\n",
    "X_train, y_train = X[:offset], y[:offset]\n",
    "\n",
    "# And put 10% in the test set.\n",
    "X_test, y_test = X[offset:], y[offset:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy:\n",
      "Percent Type I errors: 0.04488458250213736\n",
      "Percent Type II errors: 0.17882587631803934\n",
      "\n",
      "Test set accuracy:\n",
      "Percent Type I errors: 0.0339095744680851\n",
      "Percent Type II errors: 0.35904255319148937\n"
     ]
    }
   ],
   "source": [
    "# We'll make 500 iterations, use 2-deep trees, and set our loss function.\n",
    "params = {'n_estimators': 500,\n",
    "          'max_depth': 2,\n",
    "          'loss': 'deviance'}\n",
    "\n",
    "# Initialize and fit the model.\n",
    "clf = ensemble.GradientBoostingClassifier(**params)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "predict_train = clf.predict(X_train)\n",
    "predict_test = clf.predict(X_test)\n",
    "\n",
    "# Accuracy tables.\n",
    "table_train = pd.crosstab(y_train, predict_train, margins=True)\n",
    "table_test = pd.crosstab(y_test, predict_test, margins=True)\n",
    "\n",
    "train_tI_errors = table_train.loc[0.0,1.0] / table_train.loc['All','All']\n",
    "train_tII_errors = table_train.loc[1.0,0.0] / table_train.loc['All','All']\n",
    "\n",
    "test_tI_errors = table_test.loc[0.0,1.0]/table_test.loc['All','All']\n",
    "test_tII_errors = table_test.loc[1.0,0.0]/table_test.loc['All','All']\n",
    "\n",
    "print((\n",
    "    'Training set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}\\n\\n'\n",
    "    'Test set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}'\n",
    ").format(train_tI_errors, train_tII_errors, test_tI_errors, test_tII_errors))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x115f46d68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_importance = clf.feature_importances_\n",
    "\n",
    "# Make importances relative to max importance.\n",
    "feature_importance = 100.0 * (feature_importance / feature_importance.max())\n",
    "sorted_idx = np.argsort(feature_importance)\n",
    "pos = np.arange(sorted_idx.shape[0]) + .5\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.barh(pos, feature_importance[sorted_idx], align='center')\n",
    "plt.yticks(pos, X.columns[sorted_idx])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.title('Variable Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drill"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy:\n",
      "Percent Type I errors: 0.04488458250213736\n",
      "Percent Type II errors: 0.17882587631803934\n",
      "\n",
      "Test set accuracy:\n",
      "Percent Type I errors: 0.0339095744680851\n",
      "Percent Type II errors: 0.35904255319148937\n"
     ]
    }
   ],
   "source": [
    "# We'll make 500 iterations, use 2-deep trees, and set our loss function.\n",
    "params = {'n_estimators': 500,\n",
    "          'max_depth': 2,\n",
    "          'loss': 'deviance'}\n",
    "\n",
    "# Initialize and fit the model.\n",
    "clf = ensemble.GradientBoostingClassifier(**params)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "predict_train = clf.predict(X_train)\n",
    "predict_test = clf.predict(X_test)\n",
    "\n",
    "# Accuracy tables.\n",
    "table_train = pd.crosstab(y_train, predict_train, margins=True)\n",
    "table_test = pd.crosstab(y_test, predict_test, margins=True)\n",
    "\n",
    "train_tI_errors = table_train.loc[0.0,1.0] / table_train.loc['All','All']\n",
    "train_tII_errors = table_train.loc[1.0,0.0] / table_train.loc['All','All']\n",
    "\n",
    "test_tI_errors = table_test.loc[0.0,1.0]/table_test.loc['All','All']\n",
    "test_tII_errors = table_test.loc[1.0,0.0]/table_test.loc['All','All']\n",
    "\n",
    "print((\n",
    "    'Training set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}\\n\\n'\n",
    "    'Test set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}'\n",
    ").format(train_tI_errors, train_tII_errors, test_tI_errors, test_tII_errors))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping least relevant features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X.drop(['DE','SE','year','CH','CZ'],axis=1,inplace=True)\n",
    "\n",
    "# Create training and test sets.\n",
    "offset = int(X.shape[0] * 0.5)\n",
    "\n",
    "# Put 90% of the data in the training set.\n",
    "X_train, y_train = X[:offset], y[:offset]\n",
    "\n",
    "# And put 10% in the test set.\n",
    "X_test, y_test = X[offset:], y[offset:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy:\n",
      "Percent Type I errors: 0.04029523239577099\n",
      "Percent Type II errors: 0.175344105326152\n",
      "\n",
      "Test set accuracy:\n",
      "Percent Type I errors: 0.03889886295631358\n",
      "Percent Type II errors: 0.3077997207261121\n"
     ]
    }
   ],
   "source": [
    "# We'll make 500 iterations, use 2-deep trees, and set our loss function.\n",
    "params = {'n_estimators': 500,\n",
    "          'max_depth': 2,\n",
    "          'loss': 'deviance'}\n",
    "\n",
    "# Initialize and fit the model.\n",
    "clf = ensemble.GradientBoostingClassifier(**params)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "predict_train = clf.predict(X_train)\n",
    "predict_test = clf.predict(X_test)\n",
    "\n",
    "# Accuracy tables.\n",
    "table_train = pd.crosstab(y_train, predict_train, margins=True)\n",
    "table_test = pd.crosstab(y_test, predict_test, margins=True)\n",
    "\n",
    "train_tI_errors = table_train.loc[0.0,1.0] / table_train.loc['All','All']\n",
    "train_tII_errors = table_train.loc[1.0,0.0] / table_train.loc['All','All']\n",
    "\n",
    "test_tI_errors = table_test.loc[0.0,1.0]/table_test.loc['All','All']\n",
    "test_tII_errors = table_test.loc[1.0,0.0]/table_test.loc['All','All']\n",
    "\n",
    "print((\n",
    "    'Training set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}\\n\\n'\n",
    "    'Test set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}'\n",
    ").format(train_tI_errors, train_tII_errors, test_tI_errors, test_tII_errors))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv((\n",
    "    \"https://raw.githubusercontent.com/Thinkful-Ed/data-201-resources/\"\n",
    "    \"master/ESS_practice_data/ESSdata_Thinkful.csv\")).dropna()\n",
    "\n",
    "# Definine outcome and predictors.\n",
    "# Set our outcome to 0 and 1.\n",
    "y = df['partner'] - 1\n",
    "X = df.loc[:, ~df.columns.isin(['partner', 'cntry', 'idno'])]\n",
    "\n",
    "# Make the categorical variable 'country' into dummies.\n",
    "X = pd.concat([X, pd.get_dummies(df['cntry'])], axis=1)\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(kind = \"regular\")\n",
    "X_sm, Y_sm = smote.fit_sample(X,y)\n",
    "\n",
    "sm_features = pd.DataFrame(data=X_sm,columns=X.columns)\n",
    "\n",
    "sm_target = pd.DataFrame(data=Y_sm, columns = ['partner'])\n",
    "\n",
    "frames = [sm_features, sm_target]\n",
    "sm_data = pd.concat(frames,axis=1)\n",
    "\n",
    "X = sm_features\n",
    "y = sm_target.values.ravel()\n",
    "\n",
    "# Create training and test sets.\n",
    "offset = int(X.shape[0] * 0.7)\n",
    "\n",
    "# Put 90% of the data in the training set.\n",
    "X_train, y_train = X[:offset], y[:offset]\n",
    "\n",
    "# And put 10% in the test set.\n",
    "X_test, y_test = X[offset:], y[offset:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "\n",
    "selector = SelectKBest(mutual_info_classif,k=5)\n",
    "selector.fit(X,y)\n",
    "idxs_selected = selector.get_support(indices=True)\n",
    "result = X[X.columns[[idxs_selected]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy:\n",
      "Percent Type I errors: 0.01738387004844685\n",
      "Percent Type II errors: 0.1195497292675976\n",
      "\n",
      "Test set accuracy:\n",
      "Percent Type I errors: 0.0355718085106383\n",
      "Percent Type II errors: 0.29055851063829785\n"
     ]
    }
   ],
   "source": [
    "# We'll make 500 iterations, use 4-deep trees, and set our loss function.\n",
    "params = {'n_estimators': 500,\n",
    "          'max_depth': 4,\n",
    "          'loss': 'deviance'}\n",
    "\n",
    "# Initialize and fit the model.\n",
    "clf = ensemble.GradientBoostingClassifier(**params)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "predict_train = clf.predict(X_train)\n",
    "predict_test = clf.predict(X_test)\n",
    "\n",
    "# Accuracy tables.\n",
    "table_train = pd.crosstab(y_train, predict_train, margins=True)\n",
    "table_test = pd.crosstab(y_test, predict_test, margins=True)\n",
    "\n",
    "train_tI_errors = table_train.loc[0.0,1.0] / table_train.loc['All','All']\n",
    "train_tII_errors = table_train.loc[1.0,0.0] / table_train.loc['All','All']\n",
    "\n",
    "test_tI_errors = table_test.loc[0.0,1.0]/table_test.loc['All','All']\n",
    "test_tII_errors = table_test.loc[1.0,0.0]/table_test.loc['All','All']\n",
    "\n",
    "print((\n",
    "    'Training set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}\\n\\n'\n",
    "    'Test set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}'\n",
    ").format(train_tI_errors, train_tII_errors, test_tI_errors, test_tII_errors))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Using mutual information to select top features and increasing max depth to 4 yields a ~6% reduction in Type II errors in exchange for a ~2% increase in Type 2 errors. \n",
    "\n",
    "In the process of tuning the gradient boosting model, it appears that the rate of Type I and Type II errors are inversely related in which case, one must decide based on the business context what tolerances can be held for Type I and Type II error rates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
